{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicum 4.3\n",
    "## Implementeer elk gemaakt ETL-schema in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humberto de Castro\\AppData\\Local\\Temp\\ipykernel_31804\\2168663434.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x1988c946930>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB = {'servername': 'LAPTOP-LPE28RPE\\SQLEXPRESS', \n",
    "    'database': 'DEDS'}\n",
    "\n",
    "export_conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] + \n",
    "                              ';DATABASE=' + DB['database'])\n",
    "\n",
    "export_cursor = export_conn.cursor()\n",
    "export_cursor   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Database connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_sales_con = sqlite3.connect('Great_Outdoors_Data_SQLite\\go_sales.sqlite')\n",
    "go_crm_con = sqlite3.connect('Great_Outdoors_Data_SQLite\\go_crm.sqlite')\n",
    "go_staff_con = sqlite3.connect('Great_Outdoors_Data_SQLite\\go_staff.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframes aanmaken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  RETURN_REASON_CODE   RETURN_DESCRIPTION_EN TRIAL888\n",
      "0                  1       Defective product        T\n",
      "1                  2      Incomplete product        T\n",
      "2                  3   Wrong product ordered        T\n",
      "3                  4   Wrong product shipped        T\n",
      "4                  5  Unsatisfactory product        T\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humberto de Castro\\AppData\\Local\\Temp\\ipykernel_31804\\2177474246.py:49: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  Sales_staff['DATE_HIRED'] = pd.to_datetime(Sales_staff['DATE_HIRED'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "Go_staff_queries = {\n",
    "    'Course': 'SELECT * FROM Course',\n",
    "    'Training': 'SELECT * FROM Training',\n",
    "    'Sales_staff': 'SELECT * FROM Sales_staff',\n",
    "    'Satisfaction': 'SELECT * FROM Satisfaction',\n",
    "    'Satisfaction_type': 'SELECT * FROM Satisfaction_type',\n",
    "}\n",
    "\n",
    "Go_crm_queries = {\n",
    "    'Retailer_contact': 'SELECT * FROM Retailer_contact',\n",
    "    'Retailer_site' : 'SELECT * FROM Retailer_site',\n",
    "    'Retailer' : 'SELECT * FROM Retailer',\n",
    "    'Retailer_type' : 'SELECT * FROM Retailer_type',\n",
    "    'COUNTRY': 'SELECT * FROM COUNTRY',\n",
    "    'Sales_territory': 'SELECT * FROM Sales_territory'\n",
    "}\n",
    "\n",
    "Go_sales_queries = {\n",
    "    'Order_method': 'SELECT * FROM Order_method',\n",
    "    'Order_header': 'SELECT * FROM Order_header',\n",
    "    'Order_details': 'SELECT * FROM Order_details',\n",
    "    'Returned_item': 'SELECT * FROM Returned_item',\n",
    "    'Return_reason': 'SELECT * FROM Return_reason',\n",
    "    'Product': 'SELECT * FROM Product',\n",
    "    'PRODUCT_TYPE': 'SELECT * FROM PRODUCT_TYPE',\n",
    "    'PRODUCT_LINE' : 'SELECT * FROM PRODUCT_LINE',\n",
    "    'Sales_TARGETData' : 'SELECT * FROM Sales_TARGETData',\n",
    "    'Sales_branch': 'SELECT * FROM Sales_branch'\n",
    "}\n",
    "\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "# Lees elke tabel in een DataFrame\n",
    "for table_name, query in Go_staff_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, go_staff_con)\n",
    "\n",
    "for table_name, query in Go_crm_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, go_crm_con)\n",
    "\n",
    "for table_name, query in Go_sales_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, go_sales_con)\n",
    "\n",
    "\n",
    "#als je ik elk tabel als een dataframe/ variabele wil behandelen of aanroepen moet ik dit uitvoeren.\n",
    "for table_name, df in dataframes.items():\n",
    "    globals()[table_name] = df\n",
    "\n",
    "Sales_staff['DATE_HIRED'] = pd.to_datetime(Sales_staff['DATE_HIRED'], errors='coerce')\n",
    "Sales_staff['DATE_HIRED'] = Sales_staff['DATE_HIRED'].dt.date\n",
    "\n",
    "print(Return_reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform & Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retailer_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop TRIAL columns want anders veel merge problemen.\n",
    "dataframes_dict = {\n",
    "    \"Retailer_contact\": Retailer_contact,\n",
    "    \"Retailer_site\": Retailer_site,\n",
    "    \"COUNTRY\": COUNTRY,\n",
    "    \"Sales_territory\": Sales_territory,\n",
    "    \"Retailer\": Retailer,\n",
    "    \"Retailer_type\": Retailer_type\n",
    "}\n",
    "\n",
    "for name, df in dataframes_dict.items():\n",
    "    # Drop any column that contains 'TRIAL'\n",
    "    trial_cols = [col for col in df.columns if 'TRIAL' in col]\n",
    "    df.drop(columns=trial_cols, inplace=True)\n",
    "\n",
    "merge1 = pd.merge(Retailer_contact, Retailer_site, on = 'RETAILER_SITE_CODE')\n",
    "merge2 = pd.merge(merge1, COUNTRY, on = 'COUNTRY_CODE')\n",
    "merge3 = pd.merge(merge2, Sales_territory, on= 'SALES_TERRITORY_CODE')\n",
    "merge4 = pd.merge(merge3, Retailer, on= 'RETAILER_CODE')\n",
    "Retailer_dimensie = pd.merge(merge4, Retailer_type, on = 'RETAILER_TYPE_CODE')\n",
    "\n",
    "def get_category(job_position):\n",
    "    if 'Purchaser' in job_position:\n",
    "        return 'Purchaser'\n",
    "    elif 'Manager' in job_position:\n",
    "        return 'Manager'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Loop over elke rij en wijs categorie toe\n",
    "categories = []\n",
    "for index, row in Retailer_dimensie.iterrows():\n",
    "    category = get_category(row['JOB_POSITION_EN'])\n",
    "    categories.append(category)\n",
    "\n",
    "# Voeg de categorieÃ«n toe als nieuwe kolom\n",
    "Retailer_dimensie['Retailer_Position_category_Category'] = categories\n",
    "\n",
    "Retailer_dimensie = Retailer_dimensie.rename(columns= {\n",
    "    'RETAILER_CONTACT_CODE': 'Retailer_Retailer_contact_code',\n",
    "    'FIRST_NAME': 'Retailer_FIRST_NAME',\n",
    "    'LAST_NAME': 'Retailer_LAST_NAME',\n",
    "    'E_MAIL': 'Retailer_E-mail',\n",
    "    'ADDRESS1': 'Retailer_Address_ADDRESS1',\n",
    "    'ADDRESS2': 'Retailer_Address_ADDRESS2',\n",
    "    'POSTAL_ZONE': 'Retailer_Zone_POSTAL_ZONE',\n",
    "    'CITY': 'Retailer_City_CITY',\n",
    "    'REGION': 'Retailer_Region_REGION',\n",
    "    'COUNTRY_CODE': 'Retailer_Country_COUNTRY_CODE',\n",
    "    'COUNTRY_EN':'Retailer_Country_COUNTRY_EN',\n",
    "    'SALES_TERRITORY_CODE': 'Retailer_Territory_TERRITORY_CODE',\n",
    "    'TERRITORY_NAME_EN': 'Retailer_Territory_TERRITORY_NAME_EN',\n",
    "    'GENDER': 'Retailer_Gender_GENDER',\n",
    "    'RETAILER_CODE' : 'Retailer_Company_RETAILER_CODE',\n",
    "    'COMPANY_NAME' : 'Retailer_Company_COMPANY_NAME',\n",
    "    'RETAILER_TYPE_CODE': 'Retailer_Type_RETAILER_TYPE_CODE',\n",
    "    'RETAILER_TYPE_EN': 'Retailer_Type_RETAILER_TYPE_EN',\n",
    "    'JOB_POSITION_EN': 'Retailer_Position_JOB_POSITION_EN'\n",
    "\n",
    "})\n",
    "#print(Retailer_dimensie.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Retailer_dimensie.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Retailer VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Retailer_Retailer_contact_code'], row['Retailer_FIRST_NAME'], row['Retailer_LAST_NAME'],\n",
    "            row['Retailer_E-mail'], row['Retailer_Address_ADDRESS1'],\n",
    "            str(row['Retailer_Address_ADDRESS2']).replace('\\'', '\\'\\'') if pd.notna(row['Retailer_Address_ADDRESS2']) else None, \n",
    "            row['Retailer_Zone_POSTAL_ZONE'], row['Retailer_City_CITY'], row['Retailer_Region_REGION'],\n",
    "            row['Retailer_Country_COUNTRY_CODE'], row['Retailer_Country_COUNTRY_EN'],\n",
    "            row['Retailer_Territory_TERRITORY_CODE'], row['Retailer_Territory_TERRITORY_NAME_EN'],\n",
    "            row['Retailer_Gender_GENDER'], row['Retailer_Company_RETAILER_CODE'],\n",
    "            row['Retailer_Company_COMPANY_NAME'], row['Retailer_Type_RETAILER_TYPE_CODE'],\n",
    "            row['Retailer_Type_RETAILER_TYPE_EN'], row['Retailer_Position_JOB_POSITION_EN'],\n",
    "            row['Retailer_Position_category_Category']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sales_staff_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge1 = pd.merge(Sales_staff, Sales_branch, on= 'SALES_BRANCH_CODE', how= 'outer')\n",
    "#print(merge1.columns)\n",
    "\n",
    "merge2 = pd.merge(merge1, COUNTRY, on= 'COUNTRY_CODE', how= 'outer')\n",
    "#print(merge2.columns)\n",
    "Sales_staff_dimensie = pd.merge(merge2, Sales_territory, on= 'SALES_TERRITORY_CODE', how = 'outer')\n",
    "\n",
    "#conversie om .year te gebruiken.\n",
    "Sales_staff_dimensie['DATE_HIRED'] = pd.to_datetime(Sales_staff_dimensie['DATE_HIRED'])\n",
    "\n",
    "# Gebruik .dt.year om het jaar van elke datum in de Series te extraheren\n",
    "Sales_staff_dimensie['Sales_staff_In_dienst_nr'] = datetime.now().year - Sales_staff_dimensie['DATE_HIRED'].dt.year\n",
    "\n",
    "for index, row in Sales_staff_dimensie.iterrows():\n",
    "    aantal_jaar_in_dienst = row['Sales_staff_In_dienst_nr']\n",
    "\n",
    "    if aantal_jaar_in_dienst < 20:\n",
    "        Sales_staff_dimensie.at[index, 'Sales_staff_In_dienst_category_code'] = '<20 jaar'\n",
    "    else:\n",
    "        Sales_staff_dimensie.at[index, 'Sales_staff_In_dienst_category_code'] = 'â¥20 jaar'\n",
    "\n",
    "Sales_staff_dimensie = Sales_staff_dimensie.rename(columns =  {\n",
    "    'SALES_STAFF_CODE': 'Sales_staff_SALES_STAFF_CODE',\n",
    "    'FIRST_NAME': 'Sales_staff_FIRST_NAME',\n",
    "    'LAST_NAME': 'Sales_staff_LAST_NAME',\n",
    "    'POSITION_EN': 'Sales_staff_Position_POSITION_EN',\n",
    "    'EMAIL': 'Sales_staff_EMAIL',\n",
    "    'MANAGER_CODE': 'Sales_staff_Manager_MANAGER_CODE',\n",
    "    'SALES_BRANCH_CODE': 'Sales_staff_Branch_SALES_BRANCH_CODE',\n",
    "    'ADDRESS1': 'Sales_staff_ADDRESS_ADDRESS1',\n",
    "    'ADDRESS2': 'Sales_staff_ADDRESS_ADDRESS2',\n",
    "    'CITY': 'Sales_staff_City_CITY',\n",
    "    'REGION' : 'Sales_staff_Region_REGION',\n",
    "    'POSTAL_ZONE': 'Sales_staff_Zone_POSTAL_ZONE',\n",
    "    'COUNTRY_CODE': 'Sales_staff_Country_COUNTRY_CODE',\n",
    "    'COUNTRY_EN': 'Sales_staff_Country_COUNTRY_EN',\n",
    "    'SALES_TERRITORY_CODE': 'Sales_staff_Territory_TERRITORY_CODE',\n",
    "    'TERRITORY_NAME_EN': 'Sales_staff_Territory_TERRITORY_NAME_EN'\n",
    "})\n",
    "#print(Sales_staff_dimensie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ('42000', '[42000] [Microsoft][ODBC SQL Server Driver][SQL Server]The incoming tabular data stream (TDS) remote procedure call (RPC) protocol stream is incorrect. Parameter 4 (\"\"): The supplied value is not a valid instance of data type float. Check the source data for invalid values. An example of an invalid value is data of numeric type with scale greater than precision. (8023) (SQLExecDirectW)')\n",
      "INSERT INTO Sales_staff VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in Sales_staff_dimensie.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Sales_staff VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Sales_staff_SALES_STAFF_CODE'], row['Sales_staff_FIRST_NAME'], row['Sales_staff_LAST_NAME'],\n",
    "            row['Sales_staff_EMAIL'], row['Sales_staff_Zone_POSTAL_ZONE'], row['Sales_staff_ADDRESS_ADDRESS1'],\n",
    "            str(row['Sales_staff_ADDRESS_ADDRESS2']).replace('\\'', '\\'\\'') if pd.notna(row['Sales_staff_ADDRESS_ADDRESS2']) else None, row['Sales_staff_City_CITY'], row['Sales_staff_Region_REGION'],\n",
    "            row['Sales_staff_Country_COUNTRY_CODE'], row['Sales_staff_Country_COUNTRY_EN'],\n",
    "            row['Sales_staff_Territory_TERRITORY_CODE'], row['Sales_staff_Territory_TERRITORY_NAME_EN'],\n",
    "            row['Sales_staff_In_dienst_nr'], row['Sales_staff_In_dienst_category_code'],\n",
    "            row['Sales_staff_Manager_MANAGER_CODE'], row['Sales_staff_Position_POSITION_EN'],\n",
    "            row['Sales_staff_Branch_SALES_BRANCH_CODE']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Product_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Day_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Course_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  COURSE_CODE COURSE_DESCRIPTION TRIAL633\n",
      "0           1     GO Orientation        T\n",
      "1           2   GO Communication        T\n",
      "2           3         GO Sales 1        T\n",
      "3           4         GO Sales 2        T\n",
      "4           5     GO Marketing 1        T\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT * FROM course'\n",
    "\n",
    "course_dimensie = pd.read_sql_query(query, go_staff_con)\n",
    "\n",
    "# Sluit de database verbinding\n",
    "go_staff_con.close()\n",
    "\n",
    "# Toon de eerste paar rijen van de DataFrame om te bevestigen\n",
    "print(course_dimensie.head())\n",
    "\n",
    "# Hernoem de kolommen in de DataFrame\n",
    "course_dimensie = course_dimensie.rename(columns={\n",
    "    'COURSE_CODE': 'Course_COURSE_CODE',\n",
    "    'COURSE_DESCRIPTION': 'Course_COURSE_DESCRIPTION'\n",
    "})\n",
    "\n",
    "\n",
    "for index, row in course_dimensie.iterrows():\n",
    "\n",
    "    try:\n",
    "        query= f\"INSERT INTO Course VALUES ({row['Course_COURSE_CODE']}, '{row['Course_COURSE_DESCRIPTION']}' )\"\n",
    "        export_cursor.execute(query)\n",
    "    except pyodbc.Error:\n",
    "        print(query)\n",
    "\n",
    "\n",
    "export_conn.commit()\n",
    "export_cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Satisfaction_type_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction_type_dimensie = pd.DataFrame({\n",
    "    'Satisfaction_type_SATISFACTION_TYPE_CODE': [1, 2, 3, 4, 5],\n",
    "    'Satisfaction_type_SATISFACTION_TYPE_DESCRIPTION': [\n",
    "        'Not satisfied',\n",
    "        'Less than satisfied',\n",
    "        'Satisfied',\n",
    "        'Very Satisfied',\n",
    "        'More than satisfied'\n",
    "    ]\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Order_method_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_method_dimensie = pd.DataFrame({\n",
    "    'Order_method_ORDER_METHOD_CODE': [1, 2, 3, 4, 5, 7, 8],\n",
    "    'Order_method_ORDER_METHOD_EN': [\n",
    "        'Fax',\n",
    "        'Telephone',\n",
    "        'Mail',\n",
    "        'E-mail',\n",
    "        'Web',\n",
    "        'Sales visit',\n",
    "        'Special'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Return_reason_dimensie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slowly changing dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Return_reason_dimensie :** \n",
    "SDC 1 want we willen nieuwe data updaten, maar we hoeven de oude data niet het is niet relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Return_reason_RETURN_REASON_CODE Return_reason_RETURN_DESCRIPTION_EN  \\\n",
      "0                                1                   Defective product   \n",
      "1                                2                  Incomplete product   \n",
      "2                                3               Wrong product ordered   \n",
      "3                                4               Wrong product shipped   \n",
      "4                                5              Unsatisfactory product   \n",
      "5                                1                      Faulty product   \n",
      "6                                6   Product did not meet expectations   \n",
      "\n",
      "  TRIAL888  \n",
      "0        T  \n",
      "1        T  \n",
      "2        T  \n",
      "3        T  \n",
      "4        T  \n",
      "5      NaN  \n",
      "6      NaN  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Voorbeeld data aanpassing\n",
    "aanpassingen = [\n",
    "    {\"Return_reason_RETURN_REASON_CODE\": 1, \"Return_reason_RETURN_DESCRIPTION_EN\": \"Faulty product\"},  # Bij te werken\n",
    "    {\"Return_reason_RETURN_REASON_CODE\": 6, \"Return_reason_RETURN_DESCRIPTION_EN\": \"Product did not meet expectations\"}  # Nieuw\n",
    "]\n",
    "\n",
    "for aanpassing in aanpassingen:\n",
    "    code_exists = aanpassing['Return_reason_RETURN_REASON_CODE'] in Return_reason_dimensie['Return_reason_RETURN_REASON_CODE'].values\n",
    "    \n",
    "    if code_exists:\n",
    "        # DataFrame bijwerken\n",
    "        Return_reason_dimensie.loc[Return_reason_dimensie['Return_reason_RETURN_REASON_CODE'] == aanpassing['Return_reason_RETURN_REASON_CODE'], 'Return_reason_RETURN_DESCRIPTION_EN'] = aanpassing['Return_reason_RETURN_DESCRIPTION_EN']\n",
    "        \n",
    "        # SQL update\n",
    "        query_update = \"\"\"UPDATE Return_reason SET Return_reason_RETURN_DESCRIPTION_EN = ? WHERE Return_reason_RETURN_REASON_CODE = ?\"\"\"\n",
    "        params_update = (aanpassing['Return_reason_RETURN_DESCRIPTION_EN'], aanpassing['Return_reason_RETURN_REASON_CODE'])\n",
    "        export_cursor.execute(query_update, params_update)\n",
    "    else:\n",
    "        # Nieuwe rij aan DataFrame toevoegen\n",
    "        new_row_df = pd.DataFrame([aanpassing])\n",
    "        Return_reason_dimensie = pd.concat([Return_reason_dimensie, new_row_df], ignore_index=True)\n",
    "        \n",
    "        # SQL insert\n",
    "        query_insert = \"\"\"INSERT INTO Return_reason (Return_reason_RETURN_REASON_CODE, Return_reason_RETURN_DESCRIPTION_EN) VALUES (?, ?)\"\"\"\n",
    "        params_insert = (aanpassing['Return_reason_RETURN_REASON_CODE'], aanpassing['Return_reason_RETURN_DESCRIPTION_EN'])\n",
    "        export_cursor.execute(query_insert, params_insert)\n",
    "\n",
    "export_conn.commit()\n",
    "\n",
    "# Toon de aangepaste DataFrame\n",
    "print(Return_reason_dimensie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normale Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Return_reason_dimensie = Return_reason\n",
    "\n",
    "Return_reason_dimensie = Return_reason_dimensie.rename(columns= {\n",
    "    'RETURN_REASON_CODE': 'Return_reason_RETURN_REASON_CODE',\n",
    "    'RETURN_DESCRIPTION_EN': 'Return_reason_RETURN_DESCRIPTION_EN'\n",
    "})\n",
    "\n",
    "for index, row in Return_reason_dimensie.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Return_reason VALUES (?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Return_reason_RETURN_REASON_CODE'], row['Return_reason_RETURN_DESCRIPTION_EN']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Returned_item_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returned_item_feit = pd.merge(Returned_item, Return_reason, on='RETURN_REASON_CODE')\n",
    "\n",
    "Returned_item_feit['RETURN_QUANTITY'] = Returned_item_feit['RETURN_QUANTITY'].astype(float)\n",
    "\n",
    "\n",
    "Returned_item_feit = Returned_item_feit.rename(columns = {\n",
    "    'RETURN_CODE': 'Returned_item_RETURN_CODE',\n",
    "    'RETURN_DATE': 'Day_time',\n",
    "    'RETURN_QUANTITY' : 'Returned_item_RETURN_QUANTITY',\n",
    "    'RETURN_REASON_CODE' : 'Return_reason_RETURN_REASON_CODE'\n",
    "})\n",
    "\n",
    "Return_average = Returned_item_feit.groupby('Return_reason_RETURN_REASON_CODE')['Returned_item_RETURN_QUANTITY'].mean().reset_index(name='Returned_item_RETURN_AVERAGE')\n",
    "\n",
    "# Merge the average back into the main DataFrame\n",
    "Returned_item_feit = Returned_item_feit.merge(Return_average, on='Return_reason_RETURN_REASON_CODE')\n",
    "\n",
    "for index, row in Returned_item_feit.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Returned_item VALUES (?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Returned_item_RETURN_CODE'], row['Day_time'], row['Returned_item_RETURN_QUANTITY'],\n",
    "            row['Returned_item_RETURN_AVERAGE'], row['Return_reason_RETURN_REASON_CODE']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Order_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forecast_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Satisfaction_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Close**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_cursor.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deds-portofolio-7jIqONoT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
