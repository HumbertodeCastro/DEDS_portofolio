{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practicum 4.3\n",
    "## Implementeer elk gemaakt ETL-schema in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humberto de Castro\\AppData\\Local\\Temp\\ipykernel_26760\\2168663434.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "import sqlite3\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyodbc.Cursor at 0x1d986eeb8b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DB = {'servername': 'LAPTOP-LPE28RPE\\SQLEXPRESS', \n",
    "    'database': 'DEDS'}\n",
    "\n",
    "export_conn = pyodbc.connect('DRIVER={SQL Server};SERVER=' + DB['servername'] + \n",
    "                              ';DATABASE=' + DB['database'])\n",
    "\n",
    "export_cursor = export_conn.cursor()\n",
    "export_cursor   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Database connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_sales_con = sqlite3.connect('Great_Outdoors_Data_SQLite\\go_sales.sqlite')\n",
    "go_crm_con = sqlite3.connect('Great_Outdoors_Data_SQLite\\go_crm.sqlite')\n",
    "go_staff_con = sqlite3.connect('Great_Outdoors_Data_SQLite\\go_staff.sqlite')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframes aanmaken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id SALES_STAFF_CODE SALES_YEAR SALES_PERIOD  \\\n",
      "0          1                6       2021            5   \n",
      "1          2                6       2021            5   \n",
      "2          3                6       2021            5   \n",
      "3          4                6       2021            5   \n",
      "4          5                6       2021            5   \n",
      "...      ...              ...        ...          ...   \n",
      "39525  39526               83       2020            8   \n",
      "39526  39527               83       2021            3   \n",
      "39527  39528               83       2021            3   \n",
      "39528  39529               83       2021            3   \n",
      "39529  39530               83       2021            3   \n",
      "\n",
      "                 RETAILER_NAME PRODUCT_NUMBER SALES_TARGET RETAILER_CODE  \\\n",
      "0           Altitudes extrêmes             53          489            33   \n",
      "1           Altitudes extrêmes             55          666            33   \n",
      "2           Altitudes extrêmes             56          682            33   \n",
      "3              Camping Sauvage             76         3193            35   \n",
      "4              Camping Sauvage             85         7236            35   \n",
      "...                        ...            ...          ...           ...   \n",
      "39525           Golf Shop Jiro            107         4683           129   \n",
      "39526   Japan Sports Youhinten             33          497           130   \n",
      "39527  Kitanaka Tozanyouhinten             43         1564           133   \n",
      "39528  Kitanaka Tozanyouhinten             60          600           133   \n",
      "39529  Kitanaka Tozanyouhinten             61          632           133   \n",
      "\n",
      "      TRIAL888  \n",
      "0            T  \n",
      "1            T  \n",
      "2            T  \n",
      "3            T  \n",
      "4            T  \n",
      "...        ...  \n",
      "39525        T  \n",
      "39526        T  \n",
      "39527        T  \n",
      "39528        T  \n",
      "39529        T  \n",
      "\n",
      "[39530 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Humberto de Castro\\AppData\\Local\\Temp\\ipykernel_26760\\2472730092.py:49: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  Sales_staff['DATE_HIRED'] = pd.to_datetime(Sales_staff['DATE_HIRED'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "Go_staff_queries = {\n",
    "    'Course': 'SELECT * FROM Course',\n",
    "    'Training': 'SELECT * FROM Training',\n",
    "    'Sales_staff': 'SELECT * FROM Sales_staff',\n",
    "    'Satisfaction': 'SELECT * FROM Satisfaction',\n",
    "    'Satisfaction_type': 'SELECT * FROM Satisfaction_type',\n",
    "}\n",
    "\n",
    "Go_crm_queries = {\n",
    "    'Retailer_contact': 'SELECT * FROM Retailer_contact',\n",
    "    'Retailer_site' : 'SELECT * FROM Retailer_site',\n",
    "    'Retailer' : 'SELECT * FROM Retailer',\n",
    "    'Retailer_type' : 'SELECT * FROM Retailer_type',\n",
    "    'COUNTRY': 'SELECT * FROM COUNTRY',\n",
    "    'Sales_territory': 'SELECT * FROM Sales_territory'\n",
    "}\n",
    "\n",
    "Go_sales_queries = {\n",
    "    'Order_method': 'SELECT * FROM Order_method',\n",
    "    'Order_header': 'SELECT * FROM Order_header',\n",
    "    'Order_details': 'SELECT * FROM Order_details',\n",
    "    'Returned_item': 'SELECT * FROM Returned_item',\n",
    "    'Return_reason': 'SELECT * FROM Return_reason',\n",
    "    'Product': 'SELECT * FROM Product',\n",
    "    'PRODUCT_TYPE': 'SELECT * FROM PRODUCT_TYPE',\n",
    "    'PRODUCT_LINE' : 'SELECT * FROM PRODUCT_LINE',\n",
    "    'Sales_TARGETData' : 'SELECT * FROM Sales_TARGETData',\n",
    "    'Sales_branch': 'SELECT * FROM Sales_branch'\n",
    "}\n",
    "\n",
    "\n",
    "dataframes = {}\n",
    "\n",
    "# Lees elke tabel in een DataFrame\n",
    "for table_name, query in Go_staff_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, go_staff_con)\n",
    "\n",
    "for table_name, query in Go_crm_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, go_crm_con)\n",
    "\n",
    "for table_name, query in Go_sales_queries.items():\n",
    "    dataframes[table_name] = pd.read_sql_query(query, go_sales_con)\n",
    "\n",
    "\n",
    "#als je ik elk tabel als een dataframe/ variabele wil behandelen of aanroepen moet ik dit uitvoeren.\n",
    "for table_name, df in dataframes.items():\n",
    "    globals()[table_name] = df\n",
    "\n",
    "Sales_staff['DATE_HIRED'] = pd.to_datetime(Sales_staff['DATE_HIRED'], errors='coerce')\n",
    "Sales_staff['DATE_HIRED'] = Sales_staff['DATE_HIRED'].dt.date\n",
    "\n",
    "print(Sales_TARGETData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform & Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Retailer_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop TRIAL columns want anders veel merge problemen.\n",
    "dataframes_dict = {\n",
    "    \"Retailer_contact\": Retailer_contact,\n",
    "    \"Retailer_site\": Retailer_site,\n",
    "    \"COUNTRY\": COUNTRY,\n",
    "    \"Sales_territory\": Sales_territory,\n",
    "    \"Retailer\": Retailer,\n",
    "    \"Retailer_type\": Retailer_type\n",
    "}\n",
    "\n",
    "for name, df in dataframes_dict.items():\n",
    "    # Drop any column that contains 'TRIAL'\n",
    "    trial_cols = [col for col in df.columns if 'TRIAL' in col]\n",
    "    df.drop(columns=trial_cols, inplace=True)\n",
    "\n",
    "merge1 = pd.merge(Retailer_contact, Retailer_site, on = 'RETAILER_SITE_CODE')\n",
    "merge2 = pd.merge(merge1, COUNTRY, on = 'COUNTRY_CODE')\n",
    "merge3 = pd.merge(merge2, Sales_territory, on= 'SALES_TERRITORY_CODE')\n",
    "merge4 = pd.merge(merge3, Retailer, on= 'RETAILER_CODE')\n",
    "Retailer_dimensie = pd.merge(merge4, Retailer_type, on = 'RETAILER_TYPE_CODE')\n",
    "\n",
    "def get_category(job_position):\n",
    "    if 'Purchaser' in job_position:\n",
    "        return 'Purchaser'\n",
    "    elif 'Manager' in job_position:\n",
    "        return 'Manager'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Loop over elke rij en wijs categorie toe\n",
    "categories = []\n",
    "for index, row in Retailer_dimensie.iterrows():\n",
    "    category = get_category(row['JOB_POSITION_EN'])\n",
    "    categories.append(category)\n",
    "\n",
    "# Voeg de categorieën toe als nieuwe kolom\n",
    "Retailer_dimensie['Retailer_Position_category_Category'] = categories\n",
    "\n",
    "Retailer_dimensie = Retailer_dimensie.rename(columns= {\n",
    "    'RETAILER_CONTACT_CODE': 'Retailer_Retailer_contact_code',\n",
    "    'FIRST_NAME': 'Retailer_FIRST_NAME',\n",
    "    'LAST_NAME': 'Retailer_LAST_NAME',\n",
    "    'E_MAIL': 'Retailer_E-mail',\n",
    "    'ADDRESS1': 'Retailer_Address_ADDRESS1',\n",
    "    'ADDRESS2': 'Retailer_Address_ADDRESS2',\n",
    "    'POSTAL_ZONE': 'Retailer_Zone_POSTAL_ZONE',\n",
    "    'CITY': 'Retailer_City_CITY',\n",
    "    'REGION': 'Retailer_Region_REGION',\n",
    "    'COUNTRY_CODE': 'Retailer_Country_COUNTRY_CODE',\n",
    "    'COUNTRY_EN':'Retailer_Country_COUNTRY_EN',\n",
    "    'SALES_TERRITORY_CODE': 'Retailer_Territory_TERRITORY_CODE',\n",
    "    'TERRITORY_NAME_EN': 'Retailer_Territory_TERRITORY_NAME_EN',\n",
    "    'GENDER': 'Retailer_Gender_GENDER',\n",
    "    'RETAILER_CODE' : 'Retailer_Company_RETAILER_CODE',\n",
    "    'COMPANY_NAME' : 'Retailer_Company_COMPANY_NAME',\n",
    "    'RETAILER_TYPE_CODE': 'Retailer_Type_RETAILER_TYPE_CODE',\n",
    "    'RETAILER_TYPE_EN': 'Retailer_Type_RETAILER_TYPE_EN',\n",
    "    'JOB_POSITION_EN': 'Retailer_Position_JOB_POSITION_EN'\n",
    "\n",
    "})\n",
    "#print(Retailer_dimensie.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Retailer_dimensie.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Retailer VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Retailer_Retailer_contact_code'], row['Retailer_FIRST_NAME'], row['Retailer_LAST_NAME'],\n",
    "            row['Retailer_E-mail'], row['Retailer_Address_ADDRESS1'],\n",
    "            str(row['Retailer_Address_ADDRESS2']).replace('\\'', '\\'\\'') if pd.notna(row['Retailer_Address_ADDRESS2']) else None, \n",
    "            row['Retailer_Zone_POSTAL_ZONE'], row['Retailer_City_CITY'], row['Retailer_Region_REGION'],\n",
    "            row['Retailer_Country_COUNTRY_CODE'], row['Retailer_Country_COUNTRY_EN'],\n",
    "            row['Retailer_Territory_TERRITORY_CODE'], row['Retailer_Territory_TERRITORY_NAME_EN'],\n",
    "            row['Retailer_Gender_GENDER'], row['Retailer_Company_RETAILER_CODE'],\n",
    "            row['Retailer_Company_COMPANY_NAME'], row['Retailer_Type_RETAILER_TYPE_CODE'],\n",
    "            row['Retailer_Type_RETAILER_TYPE_EN'], row['Retailer_Position_JOB_POSITION_EN'],\n",
    "            row['Retailer_Position_category_Category']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Sales_staff_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merge1 = pd.merge(Sales_staff, Sales_branch, on= 'SALES_BRANCH_CODE', how= 'outer')\n",
    "#print(merge1.columns)\n",
    "\n",
    "merge2 = pd.merge(merge1, COUNTRY, on= 'COUNTRY_CODE', how= 'outer')\n",
    "#print(merge2.columns)\n",
    "Sales_staff_dimensie = pd.merge(merge2, Sales_territory, on= 'SALES_TERRITORY_CODE', how = 'outer')\n",
    "\n",
    "#conversie om .year te gebruiken.\n",
    "Sales_staff_dimensie['DATE_HIRED'] = pd.to_datetime(Sales_staff_dimensie['DATE_HIRED'])\n",
    "\n",
    "# Gebruik .dt.year om het jaar van elke datum in de Series te extraheren\n",
    "Sales_staff_dimensie['Sales_staff_In_dienst_nr'] = datetime.now().year - Sales_staff_dimensie['DATE_HIRED'].dt.year\n",
    "\n",
    "for index, row in Sales_staff_dimensie.iterrows():\n",
    "    aantal_jaar_in_dienst = row['Sales_staff_In_dienst_nr']\n",
    "\n",
    "    if aantal_jaar_in_dienst < 20:\n",
    "        Sales_staff_dimensie.at[index, 'Sales_staff_In_dienst_category_code'] = '<20 jaar'\n",
    "    else:\n",
    "        Sales_staff_dimensie.at[index, 'Sales_staff_In_dienst_category_code'] = '≥20 jaar'\n",
    "\n",
    "Sales_staff_dimensie = Sales_staff_dimensie.rename(columns =  {\n",
    "    'SALES_STAFF_CODE': 'Sales_staff_SALES_STAFF_CODE',\n",
    "    'FIRST_NAME': 'Sales_staff_FIRST_NAME',\n",
    "    'LAST_NAME': 'Sales_staff_LAST_NAME',\n",
    "    'POSITION_EN': 'Sales_staff_Position_POSITION_EN',\n",
    "    'EMAIL': 'Sales_staff_EMAIL',\n",
    "    'MANAGER_CODE': 'Sales_staff_Manager_MANAGER_CODE',\n",
    "    'SALES_BRANCH_CODE': 'Sales_staff_Branch_SALES_BRANCH_CODE',\n",
    "    'ADDRESS1': 'Sales_staff_ADDRESS_ADDRESS1',\n",
    "    'ADDRESS2': 'Sales_staff_ADDRESS_ADDRESS2',\n",
    "    'CITY': 'Sales_staff_City_CITY',\n",
    "    'REGION' : 'Sales_staff_Region_REGION',\n",
    "    'POSTAL_ZONE': 'Sales_staff_Zone_POSTAL_ZONE',\n",
    "    'COUNTRY_CODE': 'Sales_staff_Country_COUNTRY_CODE',\n",
    "    'COUNTRY_EN': 'Sales_staff_Country_COUNTRY_EN',\n",
    "    'SALES_TERRITORY_CODE': 'Sales_staff_Territory_TERRITORY_CODE',\n",
    "    'TERRITORY_NAME_EN': 'Sales_staff_Territory_TERRITORY_NAME_EN'\n",
    "})\n",
    "#print(Sales_staff_dimensie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ('42000', '[42000] [Microsoft][ODBC SQL Server Driver][SQL Server]The incoming tabular data stream (TDS) remote procedure call (RPC) protocol stream is incorrect. Parameter 4 (\"\"): The supplied value is not a valid instance of data type float. Check the source data for invalid values. An example of an invalid value is data of numeric type with scale greater than precision. (8023) (SQLExecDirectW)')\n",
      "INSERT INTO Sales_staff VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for index, row in Sales_staff_dimensie.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Sales_staff VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Sales_staff_SALES_STAFF_CODE'], row['Sales_staff_FIRST_NAME'], row['Sales_staff_LAST_NAME'],\n",
    "            row['Sales_staff_EMAIL'], row['Sales_staff_Zone_POSTAL_ZONE'], row['Sales_staff_ADDRESS_ADDRESS1'],\n",
    "            str(row['Sales_staff_ADDRESS_ADDRESS2']).replace('\\'', '\\'\\'') if pd.notna(row['Sales_staff_ADDRESS_ADDRESS2']) else None, row['Sales_staff_City_CITY'], row['Sales_staff_Region_REGION'],\n",
    "            row['Sales_staff_Country_COUNTRY_CODE'], row['Sales_staff_Country_COUNTRY_EN'],\n",
    "            row['Sales_staff_Territory_TERRITORY_CODE'], row['Sales_staff_Territory_TERRITORY_NAME_EN'],\n",
    "            row['Sales_staff_In_dienst_nr'], row['Sales_staff_In_dienst_category_code'],\n",
    "            row['Sales_staff_Manager_MANAGER_CODE'], row['Sales_staff_Position_POSITION_EN'],\n",
    "            row['Sales_staff_Branch_SALES_BRANCH_CODE']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Product_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Product_PRODUCT_NUMBER Product_Introduction_date_INTRODUCTION_DATE  \\\n",
      "0                        1                                   15-2-2011   \n",
      "1                       10                                   15-2-2011   \n",
      "2                      100                                   15-2-2011   \n",
      "3                      101                                  15-12-2019   \n",
      "4                      102                                  10-12-2019   \n",
      "..                     ...                                         ...   \n",
      "110                     95                                   15-2-2011   \n",
      "111                     96                                   15-2-2011   \n",
      "112                     97                                    5-3-2013   \n",
      "113                     98                                   15-2-2011   \n",
      "114                     99                                   15-2-2011   \n",
      "\n",
      "    Product_Type_PRODUCT_TYPE_CODE Product_Cost_PRODUCTION_COST  \\\n",
      "0                                1                            4   \n",
      "1                                1                           10   \n",
      "2                               17                            3   \n",
      "3                               18                       305.54   \n",
      "4                               18                       380.95   \n",
      "..                             ...                          ...   \n",
      "110                             16                            3   \n",
      "111                             17                        16.43   \n",
      "112                             17                           25   \n",
      "113                             17                            3   \n",
      "114                             17                            2   \n",
      "\n",
      "    Product_Margin_MARGIN    PRODUCT_IMAGE LANGUAGE      Product_PRODUCT_NAME  \\\n",
      "0                     .33    P01CE1CG1.jpg       EN       TrailChef Water Bag   \n",
      "1                      .4    P10CE1CG1.jpg       EN        TrailChef Utensils   \n",
      "2                      .5  P100OP4FA17.jpg       EN        Insect Bite Relief   \n",
      "3                     .43  P101GE5IR18.jpg       EN     Hailstorm Steel Irons   \n",
      "4                     .51  P102GE5IR18.jpg       EN  Hailstorm Titanium Irons   \n",
      "..                    ...              ...      ...                       ...   \n",
      "110                    .5   P91OP4SS16.jpg       EN                Sun Shield   \n",
      "111                   .28   P96OP4FA17.jpg       EN        Compact Relief Kit   \n",
      "112                   .28   P96OP4FA17.jpg       EN  Deluxe Family Relief Kit   \n",
      "113                    .5   P98OP4FA17.jpg       EN           Calamine Relief   \n",
      "114                    .6   P99OP4FA17.jpg       EN               Aloe Relief   \n",
      "\n",
      "                                   Product_DESCRIPTION TRIAL888_x  \\\n",
      "0    Lightweight, collapsible bag to carry liquids ...          T   \n",
      "1    Spoon, fork and knife set made of a light yet ...          T   \n",
      "2    The Insect Bite Relief helps the itching and s...          T   \n",
      "3    Iron is 17-4 stainless steel.  Shafts are grap...          T   \n",
      "4    Made entirely of pure titanium. The ultimate i...          T   \n",
      "..                                                 ...        ...   \n",
      "110  PABA free sunscreen, SPF 30, poison oak and iv...          T   \n",
      "111  A personal first aid kit is recommended for ev...          T   \n",
      "112  A complete medical kit suitable for families w...          T   \n",
      "113  Use the Calamine Relief for allergic skin reac...          T   \n",
      "114  Perfect for minor burns and sunburn, the aloe ...          T   \n",
      "\n",
      "    Product_Line_PRODUCT_LINE_CODE Product_Type_PRODUCT_TYPE_EN TRIAL888_y  \\\n",
      "0                                1                 Cooking Gear          T   \n",
      "1                                1                 Cooking Gear          T   \n",
      "2                                4                    First Aid          T   \n",
      "3                                5                        Irons          T   \n",
      "4                                5                        Irons          T   \n",
      "..                             ...                          ...        ...   \n",
      "110                              4                    Sunscreen          T   \n",
      "111                              4                    First Aid          T   \n",
      "112                              4                    First Aid          T   \n",
      "113                              4                    First Aid          T   \n",
      "114                              4                    First Aid          T   \n",
      "\n",
      "    Product_Line_PRODUCT_LINE_EN TRIAL888 Product_Category_cost_Category  \n",
      "0              Camping Equipment        T                           <100  \n",
      "1              Camping Equipment        T                           <100  \n",
      "2             Outdoor Protection        T                           <100  \n",
      "3                 Golf Equipment        T                           >100  \n",
      "4                 Golf Equipment        T                           >100  \n",
      "..                           ...      ...                            ...  \n",
      "110           Outdoor Protection        T                           <100  \n",
      "111           Outdoor Protection        T                           <100  \n",
      "112           Outdoor Protection        T                           <100  \n",
      "113           Outdoor Protection        T                           <100  \n",
      "114           Outdoor Protection        T                           <100  \n",
      "\n",
      "[115 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "merge1 = pd.merge(Product, PRODUCT_TYPE, on= 'PRODUCT_TYPE_CODE')\n",
    "#print(merge1.columns)\n",
    "\n",
    "Product_dimensie = pd.merge(merge1, PRODUCT_LINE, on = 'PRODUCT_LINE_CODE')\n",
    "#print(merge2.columns)\n",
    "\n",
    "\n",
    "for index, row in Product_dimensie.iterrows():\n",
    "    Production_cost = float(row['PRODUCTION_COST'])\n",
    "\n",
    "    if Production_cost < 100:\n",
    "        Product_dimensie.at[index, 'Product_Category_cost_Category'] = '<100'\n",
    "    else:\n",
    "        Product_dimensie.at[index, 'Product_Category_cost_Category'] = '>100'\n",
    "\n",
    "\n",
    "Product_dimensie = Product_dimensie.rename(columns = {\n",
    "    'PRODUCT_NUMBER': 'Product_PRODUCT_NUMBER',\n",
    "    'INTRODUCTION_DATE': 'Product_Introduction_date_INTRODUCTION_DATE',\n",
    "    'PRODUCTION_COST': 'Product_Cost_PRODUCTION_COST',\n",
    "    'MARGIN' : 'Product_Margin_MARGIN',\n",
    "    'PRODUCT_NAME' : 'Product_PRODUCT_NAME',\n",
    "    'DESCRIPTION' : 'Product_DESCRIPTION',\n",
    "    'PRODUCT_TYPE_CODE' : 'Product_Type_PRODUCT_TYPE_CODE',\n",
    "    'PRODUCT_TYPE_EN' : 'Product_Type_PRODUCT_TYPE_EN',\n",
    "    'PRODUCT_LINE_CODE' : 'Product_Line_PRODUCT_LINE_CODE',\n",
    "    'PRODUCT_LINE_EN' : 'Product_Line_PRODUCT_LINE_EN'\n",
    "})\n",
    "\n",
    "print(Product_dimensie)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Product_dimensie.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Product VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Product_PRODUCT_NUMBER'], row['Product_PRODUCT_NAME'], row['Product_DESCRIPTION'], row['Product_Type_PRODUCT_TYPE_CODE'],\n",
    "            row['Product_Type_PRODUCT_TYPE_EN'], row['Product_Line_PRODUCT_LINE_CODE'], row['Product_Line_PRODUCT_LINE_EN'],\n",
    "            row['Product_Introduction_date_INTRODUCTION_DATE'], row['Product_Cost_PRODUCTION_COST'], row['Product_Category_cost_Category'],\n",
    "            row['Product_Margin_MARGIN']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Day_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Course_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  COURSE_CODE COURSE_DESCRIPTION TRIAL633\n",
      "0           1     GO Orientation        T\n",
      "1           2   GO Communication        T\n",
      "2           3         GO Sales 1        T\n",
      "3           4         GO Sales 2        T\n",
      "4           5     GO Marketing 1        T\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT * FROM course'\n",
    "\n",
    "course_dimensie = pd.read_sql_query(query, go_staff_con)\n",
    "\n",
    "# Sluit de database verbinding\n",
    "go_staff_con.close()\n",
    "\n",
    "# Toon de eerste paar rijen van de DataFrame om te bevestigen\n",
    "print(course_dimensie.head())\n",
    "\n",
    "# Hernoem de kolommen in de DataFrame\n",
    "course_dimensie = course_dimensie.rename(columns={\n",
    "    'COURSE_CODE': 'Course_COURSE_CODE',\n",
    "    'COURSE_DESCRIPTION': 'Course_COURSE_DESCRIPTION'\n",
    "})\n",
    "\n",
    "\n",
    "for index, row in course_dimensie.iterrows():\n",
    "\n",
    "    try:\n",
    "        query= f\"INSERT INTO Course VALUES ({row['Course_COURSE_CODE']}, '{row['Course_COURSE_DESCRIPTION']}' )\"\n",
    "        export_cursor.execute(query)\n",
    "    except pyodbc.Error:\n",
    "        print(query)\n",
    "\n",
    "\n",
    "export_conn.commit()\n",
    "export_cursor.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Satisfaction_type_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "satisfaction_type_dimensie = pd.DataFrame({\n",
    "    'Satisfaction_type_SATISFACTION_TYPE_CODE': [1, 2, 3, 4, 5],\n",
    "    'Satisfaction_type_SATISFACTION_TYPE_DESCRIPTION': [\n",
    "        'Not satisfied',\n",
    "        'Less than satisfied',\n",
    "        'Satisfied',\n",
    "        'Very Satisfied',\n",
    "        'More than satisfied'\n",
    "    ]\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_method_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_method_dimensie = pd.DataFrame({\n",
    "    'Order_method_ORDER_METHOD_CODE': [1, 2, 3, 4, 5, 7, 8],\n",
    "    'Order_method_ORDER_METHOD_EN': [\n",
    "        'Fax',\n",
    "        'Telephone',\n",
    "        'Mail',\n",
    "        'E-mail',\n",
    "        'Web',\n",
    "        'Sales visit',\n",
    "        'Special'\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Return_reason_dimensie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Return_reason_dimensie = Return_reason\n",
    "\n",
    "Return_reason_dimensie = Return_reason_dimensie.rename(columns= {\n",
    "    'RETURN_REASON_CODE': 'Return_reason_RETURN_REASON_CODE',\n",
    "    'RETURN_DESCRIPTION_EN': 'Return_reason_RETURN_DESCRIPTION_EN'\n",
    "})\n",
    "\n",
    "for index, row in Return_reason_dimensie.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Return_reason VALUES (?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Return_reason_RETURN_REASON_CODE'], row['Return_reason_RETURN_DESCRIPTION_EN']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Returned_item_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Returned_item_feit = pd.merge(Returned_item, Return_reason, on='RETURN_REASON_CODE')\n",
    "\n",
    "Returned_item_feit['RETURN_QUANTITY'] = Returned_item_feit['RETURN_QUANTITY'].astype(float)\n",
    "\n",
    "\n",
    "Returned_item_feit = Returned_item_feit.rename(columns = {\n",
    "    'RETURN_CODE': 'Returned_item_RETURN_CODE',\n",
    "    'RETURN_DATE': 'Day_time',\n",
    "    'RETURN_QUANTITY' : 'Returned_item_RETURN_QUANTITY',\n",
    "    'RETURN_REASON_CODE' : 'Return_reason_RETURN_REASON_CODE'\n",
    "})\n",
    "\n",
    "Return_average = Returned_item_feit.groupby('Return_reason_RETURN_REASON_CODE')['Returned_item_RETURN_QUANTITY'].mean().reset_index(name='Returned_item_RETURN_AVERAGE')\n",
    "\n",
    "# Merge the average back into the main DataFrame\n",
    "Returned_item_feit = Returned_item_feit.merge(Return_average, on='Return_reason_RETURN_REASON_CODE')\n",
    "\n",
    "for index, row in Returned_item_feit.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Returned_item VALUES (?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Returned_item_RETURN_CODE'], row['Day_time'], row['Returned_item_RETURN_QUANTITY'],\n",
    "            row['Returned_item_RETURN_AVERAGE'], row['Return_reason_RETURN_REASON_CODE']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Order_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Order_OMZET Order_KORTING\n",
      "0          1253.00            6%\n",
      "1          6951.98            8%\n",
      "2          3025.56            6%\n",
      "3          4537.00           10%\n",
      "4          5012.02            9%\n",
      "...            ...           ...\n",
      "43058      2432.00           12%\n",
      "43059       432.00           12%\n",
      "43060      3200.00           12%\n",
      "43061      3168.00            5%\n",
      "43062      1008.00           18%\n",
      "\n",
      "[43063 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "merge1 = pd.merge(Order_header, Order_details, on= 'ORDER_NUMBER')\n",
    "\n",
    "merge2 = pd.merge(merge1, Retailer_contact, on = 'RETAILER_CONTACT_CODE')\n",
    "\n",
    "merge3 = pd.merge(merge2, Product, on= 'PRODUCT_NUMBER')\n",
    "\n",
    "Order_feit = pd.merge(merge3, Order_method, on = 'ORDER_METHOD_CODE')\n",
    "\n",
    "\n",
    "# Calculate 'Order_OMZET'\n",
    "Order_feit['Order_OMZET'] = Order_feit['QUANTITY'] * (pd.to_numeric(Order_feit['UNIT_PRICE']))\n",
    "\n",
    "# Locally convert 'UNIT_PRICE' and 'UNIT_SALE_PRICE' to float for the calculation\n",
    "Order_feit['Order_KORTING'] = (\n",
    "    (pd.to_numeric(Order_feit['UNIT_PRICE'], errors='coerce') - \n",
    "     pd.to_numeric(Order_feit['UNIT_SALE_PRICE'], errors='coerce')) / \n",
    "    pd.to_numeric(Order_feit['UNIT_PRICE'], errors='coerce')\n",
    ") * 100\n",
    "\n",
    "Order_feit['Order_KORTING'] = Order_feit['Order_KORTING'].map(lambda x: f\"{round(x)}%\")\n",
    "\n",
    "# Check the columns and data\n",
    "print(Order_feit[['Order_OMZET', 'Order_KORTING']])\n",
    "\n",
    "Order_feit = Order_feit.rename(columns={\n",
    "    'ORDER_NUMBER': 'Order_ORDER_NUMBER',\n",
    "    'ORDER_DATE': 'Day_date',\n",
    "    'ORDER_DETAIL_CODE': 'Order_ORDER_DETAIL_CODE',\n",
    "    'QUANTITY': 'Order_QUANTITY',\n",
    "    'UNIT_COST': 'Order_UNIT_COST',\n",
    "    'UNIT_PRICE': 'Order_UNIT_PRICE',\n",
    "    'UNIT_SALE_PRICE': 'Order_UNIT_SALE_PRICE',\n",
    "    'RETAILER_CONTACT_CODE': 'Retailer_Retailer_contact_code',\n",
    "    'PRODUCT_NUMBER': 'Product_PRODUCT_NUMBER',\n",
    "    'ORDER_METHOD_CODE': 'Order_method_ORDER_METHOD_CODE'\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Order_feit.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO [Order] VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Order_ORDER_NUMBER'],\n",
    "            row['Order_ORDER_DETAIL_CODE'],\n",
    "            row['Order_QUANTITY'],\n",
    "            row['Order_UNIT_COST'],\n",
    "            row['Order_UNIT_PRICE'],\n",
    "            row['Order_UNIT_SALE_PRICE'],\n",
    "            row['Order_OMZET'],  \n",
    "            row['Order_KORTING'],\n",
    "            row['Retailer_Retailer_contact_code'],\n",
    "            row['Product_PRODUCT_NUMBER'],\n",
    "            row['Order_method_ORDER_METHOD_CODE'],\n",
    "            row['Day_date']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Target_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(Sales_TARGETData, Sales_staff, on = 'SALES_STAFF_CODE')\n",
    "\n",
    "merge2 = pd.merge(merge1, Product, on = 'PRODUCT_NUMBER')\n",
    "\n",
    "Target_feit = pd.merge(merge2, Retailer, on = 'RETAILER_CODE')\n",
    "\n",
    "def dagen_in_maand(maand, jaar):\n",
    "    # Aantal dagen in elke maand (standaard, geen schrikkeljaar)\n",
    "    dagen = [31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31]\n",
    "    if maand == 2:  # Februari\n",
    "        # Controleer op schrikkeljaar\n",
    "        is_schrikkeljaar = jaar % 4 == 0 and (jaar % 100 != 0 or jaar % 400 == 0)\n",
    "        if is_schrikkeljaar:\n",
    "            return 29\n",
    "    return dagen[maand - 1]\n",
    "\n",
    "Target_feit['Aantal_dagen'] = Target_feit.apply(lambda row: dagen_in_maand(int(row['SALES_PERIOD']), int(row['SALES_YEAR'])), axis = 1)\n",
    "\n",
    "Target_feit['SALES_TARGET'] = pd.to_numeric(Target_feit['SALES_TARGET'], errors='coerce')\n",
    "\n",
    "Target_feit['Target_DAILY'] = Target_feit['SALES_TARGET'] / Target_feit['Aantal_dagen']\n",
    "\n",
    "Target_feit = Target_feit.rename(columns = {\n",
    "    'Id': 'Target_Id',\n",
    "    'SALES_YEAR' : 'Year_nr',\n",
    "    'SALES_TARGET': 'Target_SALES_TARGET',\n",
    "    'SALES_PERIOD': 'Target_SALES_PERIOD',\n",
    "    'SALES_STAFF_CODE': 'Sales_staff_SALES_STAFF_CODE',\n",
    "    'PRODUCT_NUMBER': 'Product_PRODUCT_NUMBER',\n",
    "    'RETAILER_CODE': 'Retailer_company_retailer_code'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Target_feit.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Target VALUES (?, ?, ?, ?, ?, ?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Target_Id'],\n",
    "            row['Year_nr'],\n",
    "            row['Target_SALES_TARGET'],\n",
    "            row['Target_SALES_PERIOD'],\n",
    "            row['Target_DAILY'],\n",
    "            row['Sales_staff_SALES_STAFF_CODE'],\n",
    "            row['Product_PRODUCT_NUMBER'],  \n",
    "            row['Retailer_company_retailer_code'],\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Forecast_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Satisfaction_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year_nr', 'Satisfaction_SALES_STAFF_CODE',\n",
      "       'Satisfaction_type_SATISFACTION_TYPE_CODE', 'TRIAL633_x', 'FIRST_NAME',\n",
      "       'LAST_NAME', 'POSITION_EN', 'WORK_PHONE', 'EXTENSION', 'FAX', 'EMAIL',\n",
      "       'DATE_HIRED', 'SALES_BRANCH_CODE', 'MANAGER_CODE', 'TRIAL633_y',\n",
      "       'SATISFACTION_TYPE_DESCRIPTION', 'TRIAL633'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "merge1 = pd.merge(Satisfaction, Sales_staff, on = 'SALES_STAFF_CODE')\n",
    "\n",
    "Satisfaction_feit = pd.merge(merge1, Satisfaction_type, on = 'SATISFACTION_TYPE_CODE')\n",
    "\n",
    "Satisfaction_feit = Satisfaction_feit.rename(columns = {\n",
    "    'YEAR' : 'Year_nr',\n",
    "    'SALES_STAFF_CODE' : 'Satisfaction_SALES_STAFF_CODE',\n",
    "    'SATISFACTION_TYPE_CODE' : 'Satisfaction_type_SATISFACTION_TYPE_CODE'\n",
    "})\n",
    "\n",
    "print(Satisfaction_feit.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Satisfaction_feit.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Satisfaction VALUES (?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Year_nr'],\n",
    "            row['Satisfaction_SALES_STAFF_CODE'],\n",
    "            row['Satisfaction_type_SATISFACTION_TYPE_CODE'],\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training_feit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Year_nr', 'Training_Sales_staff_code', 'Course_COURSE_CODE',\n",
      "       'TRIAL633_x', 'FIRST_NAME', 'LAST_NAME', 'POSITION_EN', 'WORK_PHONE',\n",
      "       'EXTENSION', 'FAX', 'EMAIL', 'DATE_HIRED', 'SALES_BRANCH_CODE',\n",
      "       'MANAGER_CODE', 'TRIAL633_y', 'COURSE_DESCRIPTION', 'TRIAL633'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#andere soort join want 2 Sales_code\n",
    "#of mischien de fk sales staff cde weghalen want anders komt gwn dubbel voor ?\n",
    "merge1 = pd.merge(Training, Sales_staff, on = 'SALES_STAFF_CODE')\n",
    "\n",
    "Training_feit = pd.merge(merge1, Course, on = 'COURSE_CODE')\n",
    "\n",
    "\n",
    "Training_feit = Training_feit.rename(columns = {\n",
    "    'YEAR' : 'Year_nr',\n",
    "    'SALES_STAFF_CODE' : 'Training_Sales_staff_code',\n",
    "    'COURSE_CODE' : 'Course_COURSE_CODE'\n",
    "})\n",
    "\n",
    "print(Training_feit.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in Training_feit.iterrows():\n",
    "    try:\n",
    "        query = \"\"\"INSERT INTO Training VALUES (?, ?, ?)\"\"\"\n",
    "        params = (\n",
    "            row['Year_nr'],\n",
    "            row['Training_Sales_staff_code'],\n",
    "            row['Course_COURSE_CODE']\n",
    "        )\n",
    "        export_cursor.execute(query, params)\n",
    "    except pyodbc.Error as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(query)\n",
    "\n",
    "export_conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Close**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_cursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slowly changing dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Return_reason_dimensie :** \n",
    "SDC 1 want we willen nieuwe data updaten, maar we hoeven de oude data niet het is niet relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Return_reason_dimensie = Return_reason\n",
    "\n",
    "Return_reason_dimensie = Return_reason_dimensie.rename(columns= {\n",
    "    'RETURN_REASON_CODE': 'Return_reason_RETURN_REASON_CODE',\n",
    "    'RETURN_DESCRIPTION_EN': 'Return_reason_RETURN_DESCRIPTION_EN'\n",
    "})\n",
    "\n",
    "# Voorbeeld data aanpassing\n",
    "aanpassingen = [\n",
    "    {\"Return_reason_RETURN_REASON_CODE\": 1, \"Return_reason_RETURN_DESCRIPTION_EN\": \"Faulty product\"},  \n",
    "    {\"Return_reason_RETURN_REASON_CODE\": 6, \"Return_reason_RETURN_DESCRIPTION_EN\": \"Product did not meet expectations\"} \n",
    "]\n",
    "\n",
    "for aanpassing in aanpassingen:\n",
    "    code_exists = aanpassing['Return_reason_RETURN_REASON_CODE'] in Return_reason_dimensie['Return_reason_RETURN_REASON_CODE'].values\n",
    "    \n",
    "    if code_exists:\n",
    "        # DataFrame bijwerken\n",
    "        Return_reason_dimensie.loc[Return_reason_dimensie['Return_reason_RETURN_REASON_CODE'] == aanpassing['Return_reason_RETURN_REASON_CODE'], 'Return_reason_RETURN_DESCRIPTION_EN'] = aanpassing['Return_reason_RETURN_DESCRIPTION_EN']\n",
    "        \n",
    "        # SQL update\n",
    "        query_update = \"\"\"UPDATE Return_reason SET Return_reason_RETURN_DESCRIPTION_EN = ? WHERE Return_reason_RETURN_REASON_CODE = ?\"\"\"\n",
    "        params_update = (aanpassing['Return_reason_RETURN_DESCRIPTION_EN'], aanpassing['Return_reason_RETURN_REASON_CODE'])\n",
    "        export_cursor.execute(query_update, params_update)\n",
    "    else:\n",
    "        # Nieuwe rij aan DataFrame toevoegen\n",
    "        new_row_df = pd.DataFrame([aanpassing])\n",
    "        Return_reason_dimensie = pd.concat([Return_reason_dimensie, new_row_df], ignore_index=True)\n",
    "        \n",
    "        # SQL insert\n",
    "        query_insert = \"\"\"INSERT INTO Return_reason (Return_reason_RETURN_REASON_CODE, Return_reason_RETURN_DESCRIPTION_EN) VALUES (?, ?)\"\"\"\n",
    "        params_insert = (aanpassing['Return_reason_RETURN_REASON_CODE'], aanpassing['Return_reason_RETURN_DESCRIPTION_EN'])\n",
    "        export_cursor.execute(query_insert, params_insert)\n",
    "\n",
    "export_conn.commit()\n",
    "\n",
    "# Toon de aangepaste DataFrame\n",
    "print(Return_reason_dimensie)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deds-portofolio-7jIqONoT-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
